{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7957,"status":"ok","timestamp":1682257304479,"user":{"displayName":"Kang Eun Jeon","userId":"13526126682032845612"},"user_tz":-540},"id":"V5DoFhtAutdT"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1682257304480,"user":{"displayName":"Kang Eun Jeon","userId":"13526126682032845612"},"user_tz":-540},"id":"8QgcPHLvuoxJ"},"outputs":[],"source":["class Conv2dSDK(torch.nn.Module):\n","  def __init__(self, kernel, pw_width, pw_height):\n","    super().__init__()\n","\n","    if kernel.shape[2] != kernel.shape[3]:\n","      raise ValueError(\"Kernel is not square. Rectangular Kernel not supported.\")\n","\n","    if pw_height < kernel.shape[2] or pw_width < kernel.shape[3]:\n","      raise ValueError(\"Parallel window is smaller than the kernel.\")\n","\n","    if pw_height == 3 and pw_width == 3:\n","      print(\"WARNING: Parallel window size is 3. Use Conv2dIm2col instead.\")\n","\n","    self.kernel = kernel\n","    self.out_channels = kernel.shape[0]\n","    self.in_channels = kernel.shape[1]\n","    self.kernel_size = kernel.shape[2]\n","\n","    self.pw_width = pw_width\n","    self.pw_height = pw_height\n","\n","    self.weight_map = torch.nn.Parameter(self._gen_SDK_mapping())\n","\n","  def _ordered_pairs_sum(self, x):\n","    a = torch.arange(x + 1)\n","    b = x - a\n","    pairs = torch.stack((a, b), dim=1)\n","    return pairs\n","\n","  def _gen_SDK_mapping(self):\n","    h_diff = self.pw_height - self.kernel_size\n","    w_diff = self.pw_width - self.kernel_size\n","\n","    ver_pads = self._ordered_pairs_sum(h_diff)\n","    hor_pads = self._ordered_pairs_sum(w_diff)\n","\n","    SDK_mapping = []\n","\n","    for i in range(len(ver_pads)):\n","      for j in range(len(hor_pads)):\n","        p2d = (hor_pads[j,0], hor_pads[j,1], ver_pads[i,0], ver_pads[i,1])\n","        padded_kernel =  F.pad(self.kernel, p2d, mode='constant', value=0)\n","        flat_kernel = padded_kernel.view(self.out_channels, -1)\n","\n","        SDK_mapping.append(flat_kernel)\n","\n","    SDK_mapping = torch.concat(SDK_mapping)\n","\n","    return SDK_mapping\n","\n","  def _forward(self, x):\n","    num, depth, height, width = x.shape\n","\n","    stride_ver = self.pw_height - self.kernel_size + 1\n","    stride_hor = self.pw_width  - self.kernel_size + 1\n","\n","    pad_ver = (height + 2 - self.pw_height) % stride_ver\n","    pad_hor = (width  + 2 - self.pw_width)  % stride_hor\n","\n","    slide_ver = math.ceil((height + 2 - self.pw_height) / stride_ver) + 1\n","    slide_hor = math.ceil((width  + 2 - self.pw_width ) / stride_hor) + 1\n","\n","\n","    padded_x = F.pad(x, (1, 1 + pad_hor, 1, 1 + pad_ver), \n","                     mode='constant', value=0)\n","\n","    flat_windows = F.unfold(padded_x, \n","                            kernel_size=(self.pw_height, self.pw_width), \n","                            stride=(stride_ver, stride_hor)).transpose(1,2)\n","\n","    lin_out = F.linear(flat_windows, self.weight_map)\n","    # print(lin_out.shape)\n","\n","    lin_out = lin_out.reshape(num, slide_ver, slide_hor, \n","                              self.pw_height - self.kernel_size + 1, \n","                              self.pw_width  - self.kernel_size + 1, self.out_channels)\n","    # print(lin_out.shape)\n","\n","    lin_out = lin_out.transpose(2,3)\n","    lin_out = lin_out.reshape(num, \n","                              height+int(pad_ver/2), \n","                              width+int(pad_hor/2), \n","                              self.out_channels)\n","    lin_out = lin_out.transpose(3,1).transpose(3,2)\n","    print(lin_out.shape)\n","    lin_out = lin_out[:,:,:height,:width]\n","    return lin_out\n","\n","  def forward(self, input):\n","    return self._forward(input)\n","\n","  def string(self):\n","    return 'testing'"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1682263012269,"user":{"displayName":"Kang Eun Jeon","userId":"13526126682032845612"},"user_tz":-540},"id":"314MeC2qTD_b"},"outputs":[],"source":["class Conv2dSDK_QR(Conv2dSDK):\n","  def __init__(self, kernel, pw_width, pw_height, rank):\n","    super().__init__(kernel, pw_width, pw_height)\n","    self.rank = rank\n","    Q, R = self._SVD()\n","    self.original_weight_map = torch.tensor(self.weight_map)\n","    self.Q = torch.nn.Parameter(torch.tensor(Q))\n","    self.R = torch.nn.Parameter(torch.tensor(R))\n","    self.weight_map = torch.nn.Parameter(torch.matmul(self.Q, self.R))\n","    # self.new_weight_map = torch.randn(img_num, input_channel, img_width, img_width)\n","\n","  def _SVD(self):\n","    u, s, vh = np.linalg.svd(self.weight_map.cpu().detach().numpy(), full_matrices=False)\n","    u_t = u[:,0:self.rank]\n","    s_t = np.diag(s[:self.rank])\n","    v_t = vh[:self.rank,:]\n","    # print(u_t.shape)\n","    # print(s_t.shape)\n","    # print(v_t.shape)\n","    Q = u_t@s_t\n","    R = v_t\n","    # print(Q.shape)\n","    # print(R.shape)\n","    return Q, R"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1682257987617,"user":{"displayName":"Kang Eun Jeon","userId":"13526126682032845612"},"user_tz":-540},"id":"eF2RD8hMWSJK"},"outputs":[],"source":["def test_script():\n","  # gen random data\n","  img_num = 1\n","  img_width = 8\n","  input_channel = 32\n","  kernel_size = 3\n","  output_channel = 64\n","\n","  # create a 1D tensor with values ranging from 0 to 8*8*64-1\n","  # img = torch.arange(img_num*img_width*img_width*input_channel)\n","  # img = img.reshape(img_num, input_channel, img_width, img_width)\n","  img = torch.randn(img_num, input_channel, img_width, img_width)\n","\n","  # create a 4D random tensor\n","  kernel = torch.randn(output_channel, input_channel, kernel_size, kernel_size)\n","  # kernel2 = torch.randn(output_channel, input_channel, kernel_size, kernel_size)\n","\n","  my_conv1 = Conv2dSDK_QR(rank=40, kernel=kernel, pw_width=3, pw_height=3)\n","  lin_out = my_conv1(img)\n","  output = F.conv2d(img, kernel, padding=1)\n","\n","  # See that the two operation is identical\n","  l1_norm = torch.norm(lin_out - output, p=1)\n","  print(l1_norm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wEQlT6Wprhkp"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN8QXk37mQcdJ85vJaf3Agb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
